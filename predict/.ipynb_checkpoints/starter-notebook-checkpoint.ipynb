{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c7e849a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T09:24:53.643384Z",
     "start_time": "2021-06-11T09:24:53.622385Z"
    }
   },
   "source": [
    "# Regression Predict Student Solution\n",
    "\n",
    "© Explore Data Science Academy\n",
    "\n",
    "---\n",
    "### Honour Code\n",
    "\n",
    "I {**HARMONY, MNCUBE**}, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the [EDSA honour code](https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract.\n",
    "\n",
    "### Predict Overview: Spain Electricity Shortfall Challenge\n",
    "\n",
    "The government of Spain is considering an expansion of it's renewable energy resource infrastructure investments. As such, they require information on the trends and patterns of the countries renewable sources and fossil fuel energy generation. Your company has been awarded the contract to:\n",
    "\n",
    "- 1. analyse the supplied data;\n",
    "- 2. identify potential errors in the data and clean the existing data set;\n",
    "- 3. determine if additional features can be added to enrich the data set;\n",
    "- 4. build a model that is capable of forecasting the three hourly demand shortfalls;\n",
    "- 5. evaluate the accuracy of the best machine learning model;\n",
    "- 6. determine what features were most important in the model’s prediction decision, and\n",
    "- 7. explain the inner working of the model to a non-technical audience.\n",
    "\n",
    "Formally the problem statement was given to you, the senior data scientist, by your manager via email reads as follow:\n",
    "\n",
    "> In this project you are tasked to model the shortfall between the energy generated by means of fossil fuels and various renewable sources - for the country of Spain. The daily shortfall, which will be referred to as the target variable, will be modelled as a function of various city-specific weather features such as `pressure`, `wind speed`, `humidity`, etc. As with all data science projects, the provided features are rarely adequate predictors of the target variable. As such, you are required to perform feature engineering to ensure that you will be able to accurately model Spain's three hourly shortfalls.\n",
    " \n",
    "On top of this, she has provided you with a starter notebook containing vague explanations of what the main outcomes are. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05600c92",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Loading Data</a>\n",
    "\n",
    "<a href=#three>3. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#four>4. Data Engineering</a>\n",
    "\n",
    "<a href=#five>5. Modeling</a>\n",
    "\n",
    "<a href=#six>6. Model Performance</a>\n",
    "\n",
    "<a href=#seven>7. Model Explanations</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997462e2",
   "metadata": {},
   "source": [
    " <a id=\"one\"></a>\n",
    "## 1. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Importing Packages ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to import, and briefly discuss, the libraries that will be used throughout your analysis and modelling. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "475dbe93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:30:53.800892Z",
     "start_time": "2021-06-23T10:30:50.215449Z"
    }
   },
   "outputs": [],
   "source": [
    "# Libraries for data loading, data manipulation and data visulisation\n",
    "import pandas as pd\n",
    "import calendar\n",
    "# Libraries for data preparation and model building\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler as SS\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setting global constants to ensure notebook results are reproducible\n",
    "#PARAMETER_CONSTANT = ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a6718",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "## 2. Loading the Data\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Loading the data ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to load the data from the `df_train` file into a DataFrame. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbbb6c18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:49:35.311495Z",
     "start_time": "2021-06-28T08:49:35.295494Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time</th>\n",
       "      <th>Madrid_wind_speed</th>\n",
       "      <th>Valencia_wind_deg</th>\n",
       "      <th>Bilbao_rain_1h</th>\n",
       "      <th>Valencia_wind_speed</th>\n",
       "      <th>Seville_humidity</th>\n",
       "      <th>Madrid_humidity</th>\n",
       "      <th>Bilbao_clouds_all</th>\n",
       "      <th>Bilbao_wind_speed</th>\n",
       "      <th>...</th>\n",
       "      <th>Madrid_temp_max</th>\n",
       "      <th>Barcelona_temp</th>\n",
       "      <th>Bilbao_temp_min</th>\n",
       "      <th>Bilbao_temp</th>\n",
       "      <th>Barcelona_temp_min</th>\n",
       "      <th>Bilbao_temp_max</th>\n",
       "      <th>Seville_temp_min</th>\n",
       "      <th>Madrid_temp</th>\n",
       "      <th>Madrid_temp_min</th>\n",
       "      <th>load_shortfall_3h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01 03:00:00</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>level_5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>74.333333</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>265.938000</td>\n",
       "      <td>281.013000</td>\n",
       "      <td>269.338615</td>\n",
       "      <td>269.338615</td>\n",
       "      <td>281.013000</td>\n",
       "      <td>269.338615</td>\n",
       "      <td>274.254667</td>\n",
       "      <td>265.938000</td>\n",
       "      <td>265.938000</td>\n",
       "      <td>6715.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 06:00:00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>level_10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>78.333333</td>\n",
       "      <td>64.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>266.386667</td>\n",
       "      <td>280.561667</td>\n",
       "      <td>270.376000</td>\n",
       "      <td>270.376000</td>\n",
       "      <td>280.561667</td>\n",
       "      <td>270.376000</td>\n",
       "      <td>274.945000</td>\n",
       "      <td>266.386667</td>\n",
       "      <td>266.386667</td>\n",
       "      <td>4171.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-01 09:00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>level_9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>71.333333</td>\n",
       "      <td>64.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>272.708667</td>\n",
       "      <td>281.583667</td>\n",
       "      <td>275.027229</td>\n",
       "      <td>275.027229</td>\n",
       "      <td>281.583667</td>\n",
       "      <td>275.027229</td>\n",
       "      <td>278.792000</td>\n",
       "      <td>272.708667</td>\n",
       "      <td>272.708667</td>\n",
       "      <td>4274.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-01-01 12:00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>level_8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.333333</td>\n",
       "      <td>56.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>281.895219</td>\n",
       "      <td>283.434104</td>\n",
       "      <td>281.135063</td>\n",
       "      <td>281.135063</td>\n",
       "      <td>283.434104</td>\n",
       "      <td>281.135063</td>\n",
       "      <td>285.394000</td>\n",
       "      <td>281.895219</td>\n",
       "      <td>281.895219</td>\n",
       "      <td>5075.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-01-01 15:00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>level_7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>280.678437</td>\n",
       "      <td>284.213167</td>\n",
       "      <td>282.252063</td>\n",
       "      <td>282.252063</td>\n",
       "      <td>284.213167</td>\n",
       "      <td>282.252063</td>\n",
       "      <td>285.513719</td>\n",
       "      <td>280.678437</td>\n",
       "      <td>280.678437</td>\n",
       "      <td>6620.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 time  Madrid_wind_speed Valencia_wind_deg   \n",
       "0           0  2015-01-01 03:00:00           0.666667           level_5  \\\n",
       "1           1  2015-01-01 06:00:00           0.333333          level_10   \n",
       "2           2  2015-01-01 09:00:00           1.000000           level_9   \n",
       "3           3  2015-01-01 12:00:00           1.000000           level_8   \n",
       "4           4  2015-01-01 15:00:00           1.000000           level_7   \n",
       "\n",
       "   Bilbao_rain_1h  Valencia_wind_speed  Seville_humidity  Madrid_humidity   \n",
       "0             0.0             0.666667         74.333333        64.000000  \\\n",
       "1             0.0             1.666667         78.333333        64.666667   \n",
       "2             0.0             1.000000         71.333333        64.333333   \n",
       "3             0.0             1.000000         65.333333        56.333333   \n",
       "4             0.0             1.000000         59.000000        57.000000   \n",
       "\n",
       "   Bilbao_clouds_all  Bilbao_wind_speed  ...  Madrid_temp_max  Barcelona_temp   \n",
       "0                0.0           1.000000  ...       265.938000      281.013000  \\\n",
       "1                0.0           1.000000  ...       266.386667      280.561667   \n",
       "2                0.0           1.000000  ...       272.708667      281.583667   \n",
       "3                0.0           1.000000  ...       281.895219      283.434104   \n",
       "4                2.0           0.333333  ...       280.678437      284.213167   \n",
       "\n",
       "   Bilbao_temp_min  Bilbao_temp  Barcelona_temp_min  Bilbao_temp_max   \n",
       "0       269.338615   269.338615          281.013000       269.338615  \\\n",
       "1       270.376000   270.376000          280.561667       270.376000   \n",
       "2       275.027229   275.027229          281.583667       275.027229   \n",
       "3       281.135063   281.135063          283.434104       281.135063   \n",
       "4       282.252063   282.252063          284.213167       282.252063   \n",
       "\n",
       "   Seville_temp_min Madrid_temp  Madrid_temp_min  load_shortfall_3h  \n",
       "0        274.254667  265.938000       265.938000        6715.666667  \n",
       "1        274.945000  266.386667       266.386667        4171.666667  \n",
       "2        278.792000  272.708667       272.708667        4274.666667  \n",
       "3        285.394000  281.895219       281.895219        5075.666667  \n",
       "4        285.513719  280.678437       280.678437        6620.666667  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('df_train.csv') # load the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca2147fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0 ->: int64\n",
      "time ->: object\n",
      "Madrid_wind_speed ->: float64\n",
      "Valencia_wind_deg ->: object\n",
      "Bilbao_rain_1h ->: float64\n",
      "Valencia_wind_speed ->: float64\n",
      "Seville_humidity ->: float64\n",
      "Madrid_humidity ->: float64\n",
      "Bilbao_clouds_all ->: float64\n",
      "Bilbao_wind_speed ->: float64\n",
      "Seville_clouds_all ->: float64\n",
      "Bilbao_wind_deg ->: float64\n",
      "Barcelona_wind_speed ->: float64\n",
      "Barcelona_wind_deg ->: float64\n",
      "Madrid_clouds_all ->: float64\n",
      "Seville_wind_speed ->: float64\n",
      "Barcelona_rain_1h ->: float64\n",
      "Seville_pressure ->: object\n",
      "Seville_rain_1h ->: float64\n",
      "Bilbao_snow_3h ->: float64\n",
      "Barcelona_pressure ->: float64\n",
      "Seville_rain_3h ->: float64\n",
      "Madrid_rain_1h ->: float64\n",
      "Barcelona_rain_3h ->: float64\n",
      "Valencia_snow_3h ->: float64\n",
      "Madrid_weather_id ->: float64\n",
      "Barcelona_weather_id ->: float64\n",
      "Bilbao_pressure ->: float64\n",
      "Seville_weather_id ->: float64\n",
      "Valencia_pressure ->: float64\n",
      "Seville_temp_max ->: float64\n",
      "Madrid_pressure ->: float64\n",
      "Valencia_temp_max ->: float64\n",
      "Valencia_temp ->: float64\n",
      "Bilbao_weather_id ->: float64\n",
      "Seville_temp ->: float64\n",
      "Valencia_humidity ->: float64\n",
      "Valencia_temp_min ->: float64\n",
      "Barcelona_temp_max ->: float64\n",
      "Madrid_temp_max ->: float64\n",
      "Barcelona_temp ->: float64\n",
      "Bilbao_temp_min ->: float64\n",
      "Bilbao_temp ->: float64\n",
      "Barcelona_temp_min ->: float64\n",
      "Bilbao_temp_max ->: float64\n",
      "Seville_temp_min ->: float64\n",
      "Madrid_temp ->: float64\n",
      "Madrid_temp_min ->: float64\n",
      "load_shortfall_3h ->: float64\n"
     ]
    }
   ],
   "source": [
    "# Print column names and data types\n",
    "for column_name, data_type in df.dtypes.items():\n",
    "    print(f\"{column_name} ->: {data_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377fa756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_variance(df):\n",
    "    variances = df.var()\n",
    "    return variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293905a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function with your DataFrame\n",
    "column_variances = calculate_variance(df['load_shortfall_3h'])\n",
    "# Print the variances\n",
    "print(column_variances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81132ab3",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## 3. Exploratory Data Analysis (EDA)\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Exploratory data analysis ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to perform an in-depth analysis of all the variables in the DataFrame. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e805134e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:52:37.824204Z",
     "start_time": "2021-06-28T08:52:37.811206Z"
    }
   },
   "outputs": [],
   "source": [
    "# look at data statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb74182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot relevant feature interactions\n",
    "\n",
    "# Group the data by date and calculate the mean of the target variable (load_shortfall_3h)\n",
    "grouped_data = df.groupby('Month')['load_shortfall_3h'].mean()\n",
    "\n",
    "# Convert month names to month numbers for sorting\n",
    "month_order = [calendar.month_name[i] for i in range(1, 13)]\n",
    "\n",
    "# Sort the grouped data by month order\n",
    "grouped_data = grouped_data.reindex(month_order)\n",
    "\n",
    "# Plot the line graph\n",
    "plt.plot(grouped_data.index, grouped_data.values)\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Load Shortfall (Energy)')\n",
    "plt.title('Load Shortfall over Time')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802aa594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by date and calculate the mean of the target variable (load_shortfall_3h)\n",
    "grouped_data = df.groupby('Season')['Valencia_pressure'].mean()\n",
    "\n",
    "# Increase the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Convert month names to month numbers for sorting\n",
    "month_order = [calendar.month_name[i] for i in range(1, 13)]\n",
    "\n",
    "# Sort the grouped data by month order\n",
    "grouped_data = grouped_data.reindex(month_order)\n",
    "\n",
    "# Create a line plot for Valencia_pressure to see if it follows a linear pattenr of any sort\n",
    "plt.plot(grouped_data.index, grouped_data.values)\n",
    "plt.xlabel('Season')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Valencia Pressure')\n",
    "plt.title('Valencia Pressure Per Season')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f229e09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a box plot of the DataFrame\n",
    "plt.figure(figsize=(12, 6))  # Set the figure size\n",
    "df.boxplot()  # Create the box plot\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better visibility\n",
    "plt.title('Spread of Data - Box Plot')  # Set the title of the plot\n",
    "plt.xlabel('Columns')  # Set the x-axis label\n",
    "plt.ylabel('Values')  # Set the y-axis label\n",
    "plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd6ee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de51df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# have a look at feature distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa93ec6",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "## 4. Data Engineering\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Data engineering ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to: clean the dataset, and possibly create new features - as identified in the EDA phase. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059c2f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove missing values/ features\n",
    "def check_null_values(df):\n",
    "    \"\"\"Returns a summary of null values in each column of a pandas DataFrame\"\"\"\n",
    "    \n",
    "    null_counts = df.isnull().sum()\n",
    "    null_percentage = round(null_counts / len(df) * 100, 2)\n",
    "    \n",
    "    null_summary = pd.concat([null_counts, null_percentage], axis=1)\n",
    "    null_summary.columns = ['# of Null Values', '% of Null Values']\n",
    "    null_summary.sort_values(by='# of Null Values', ascending=False, inplace=True)\n",
    "    return null_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f76af69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the Unnamed: 0 column using the .drop() method\n",
    "df.drop(\"Unnamed: 0\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d314fa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the time column to a datetime data type using pd.to_datetime() for time-based analysis.\n",
    "df['time'] = pd.to_datetime(df['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369fe0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check any rows with missing values\n",
    "nulls = check_null_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77aba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84eea17b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 26\u001b[0m\n\u001b[0;32m     22\u001b[0m df[float_columns] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(df[float_columns])\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Print the updated DataFrame\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Extract the month from the \"date\" column and create a new column \"Month\"\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[38;5;241m.\u001b[39mmonth\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Define a dictionary to map month numbers to month names\u001b[39;00m\n\u001b[0;32m     29\u001b[0m month_names \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJanuary\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;241m2\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFebruary\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;241m12\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDecember\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     42\u001b[0m }\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5989\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5983\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5984\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5985\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5986\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5987\u001b[0m ):\n\u001b[0;32m   5988\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5989\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\accessors.py:580\u001b[0m, in \u001b[0;36mCombinedDatetimelikeProperties.__new__\u001b[1;34m(cls, data)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_period_dtype(data\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PeriodProperties(data, orig)\n\u001b[1;32m--> 580\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .dt accessor with datetimelike values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "# create new features\n",
    "# Convert the date column to a pandas datetime object\n",
    "\n",
    "# Convert the \"date\" column to datetime type if it's not already\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "#Separate the date from time str\n",
    "df['date'] = df['time'].dt.date\n",
    "# Extract the hour from the date column and create a new column called hour\n",
    "df['time'] = df['time'].dt.time\n",
    "\n",
    "\n",
    "# Select only the float columns in the DataFrame\n",
    "float_columns = df.select_dtypes(include=['float']).columns\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply Min-Max scaling to the float columns\n",
    "df[float_columns] = scaler.fit_transform(df[float_columns])\n",
    "# Print the updated DataFrame\n",
    "\n",
    "# Extract the month from the \"date\" column and create a new column \"Month\"\n",
    "df['Month'] = df['date'].dt.month\n",
    "\n",
    "# Define a dictionary to map month numbers to month names\n",
    "month_names = {\n",
    "    1: 'January',\n",
    "    2: 'February',\n",
    "    3: 'March',\n",
    "    4: 'April',\n",
    "    5: 'May',\n",
    "    6: 'June',\n",
    "    7: 'July',\n",
    "    8: 'August',\n",
    "    9: 'September',\n",
    "    10: 'October',\n",
    "    11: 'November',\n",
    "    12: 'December'\n",
    "}\n",
    "\n",
    "# Map the month numbers to month names\n",
    "df['Month'] = df['Month'].map(month_names)\n",
    "\n",
    "# Define a dictionary to map months to seasons\n",
    "seasons = {\n",
    "    'January': 'Winter',\n",
    "    'February': 'Winter',\n",
    "    'March': 'Spring',\n",
    "    'April': 'Spring',\n",
    "    'May': 'Spring',\n",
    "    'June': 'Summer',\n",
    "    'July': 'Summer',\n",
    "    'August': 'Summer',\n",
    "    'September': 'Fall',\n",
    "    'October': 'Fall',\n",
    "    'November': 'Fall',\n",
    "    'December': 'Winter'\n",
    "}\n",
    "\n",
    "# Map the months to seasons\n",
    "df['Season'] = df['Month'].map(seasons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86d9c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the numeric part from the \"Valencia_wind_deg\" column\n",
    "df['Valencia_wind_deg'] = df['Valencia_wind_deg'].apply(lambda x: int(x.split('_')[1]))\n",
    "\n",
    "# Fill missing values with the mean\n",
    "mean_pressure = df['Valencia_pressure'].mean()\n",
    "df['Valencia_pressure'] = df['Valencia_pressure'].fillna(mean_pressure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59692724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11d428f7",
   "metadata": {},
   "source": [
    "**Z-Score Normalization**\n",
    "Z-score normalization (also known as standardization) transforms the features to have zero mean and unit variance. You can use the StandardScaler class from scikit-learn for this normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b2d523",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "## 5. Modelling\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Modelling ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to create one or more regression models that are able to accurately predict the thee hour load shortfall. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2344b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "# Split the data into training and test sets\n",
    "X = grouped_data[['demand', 'supply']]\n",
    "y = grouped_data['shortfall']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c58df02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create targets and features dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d073e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one or more ML models\n",
    "# Train a Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70c15d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate one or more ML models\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print('Mean Squared Error:', mse)\n",
    "print('R-squared:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b530251",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "## 6. Model Performance\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model performance ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to compare the relative performance of the various trained ML models on a holdout dataset and comment on what model is the best and why. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3874a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose best model and motivate why it is the best choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4f7312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8ad0c0d",
   "metadata": {},
   "source": [
    "<a id=\"seven\"></a>\n",
    "## 7. Model Explanations\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model explanation ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to discuss how the best performing model works in a simple way so that both technical and non-technical stakeholders can grasp the intuition behind the model's inner workings. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff741c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discuss chosen methods logic\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
